{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** $\\sigma$-algebra **\n",
    "\n",
    "A $\\sigma$-algebra on $\\Omega$ is a collection $\\mathcal{A} \\subset 2^\\Omega$ s.t. \n",
    "* $E\\in\\mathcal{A} \\Rightarrow E^c\\in\\mathcal{A}$,\n",
    "* $E_1,E_2,...\\in\\mathcal{A} \\Rightarrow \\cup_{i=1}^{\\infty}E_i\\in\\mathcal{A}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Probability Measure**\n",
    "\n",
    "A probability measure $P$ on $(\\Omega,\\mathcal{A})$ is a function $P:\\mathcal{A}\\rightarrow[0,1]$ s.t.\n",
    "* $P(\\emptyset)=0, P(\\Omega)=1$,\n",
    "* $P(\\cup_{i=1}^\\infty E_i) = \\sum_{i=1}^\\infty P(E_i)$ for any $E_1,E_2,...\\in\\mathcal{A}$ that are pairwise disjoint.\n",
    "\n",
    "*REMARKS*\n",
    "* $P(E\\cup F) = P(E)+P(F)-P(E\\cap F)$, for any $E,F\\in \\mathcal{A}$,\n",
    "* $P(E) = 1 - P(E^c)$, for all $E\\in\\mathcal{A}$,\n",
    "* If $E\\subset F$ then $P(E)\\leq P(F)$, for all $E,F\\in \\mathcal{A}$,\n",
    "* If $E_1,E_2,...\\in\\mathcal{A}$ then $P(\\cup_{i=1}^\\infty E_i) \\leq \\sum_{i=1}^\\infty P(E_i)$,\n",
    "* If $E_1\\subset E_2\\subset ...$ then $P(\\cup_{i=1}^\\infty E_i) = lim_{i\\rightarrow\\infty}P(E_i)$,\n",
    "* If $E_1\\supset E_2\\supset ...$ then $P(\\cap_{i=1}^\\infty E_i) = lim_{i\\rightarrow\\infty}P(E_i)$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cumulative Distribution Function (CDF) **\n",
    "\n",
    "A $CDF$ is a function $F:\\mathbf{R}\\rightarrow\\mathbf{R}$ s.t. \n",
    "* $x\\leq y \\Rightarrow F(x)\\leq F(y)$, $\\forall x,y\\in\\mathbf{R}$,\n",
    "* $lim_{x\\rightarrow a^+} F(x) = F(a)$,\n",
    "* $lim_{x\\rightarrow\\infty}F(x) = 1$,\n",
    "* $lim_{x\\rightarrow -\\infty}F(x) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prob/Measure Theorem **\n",
    "\n",
    "$F(x) = P((-\\infty,x])$ defines an equivalence between $CDF$s $F$ and (Borel) Probability Measures $P$ on $\\mathbf{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Important Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bayes' Rule **\n",
    "\n",
    "* $P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$, if $P(A)>0, P(B)>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Chain Rule **\n",
    "\n",
    "* If $A_1,...,A_n$, and $P(A_1\\cap ... \\cap A_{n-1}) > 0$, then $P(A_1\\cap ... \\cap A_{n}) = P(A_1)P(A_2|A_1)...P(A_n|A_1,...,A_{n-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Partition Rule **\n",
    "\n",
    "A *partition* of $\\Omega$ is a finite or countable collection $\\{B_i\\}, B_i\\subset 2^\\Omega$, s.t. \n",
    "* $\\cup_iB_i = \\Omega$,\n",
    "* $B_i\\cap B_j = \\emptyset, \\forall(i\\neq j)$.\n",
    "\n",
    "$P(A)=\\sum_iP(A\\cap B_i)$ for any partition $\\{B_i\\}$ of $\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Random Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Definition **\n",
    "\n",
    "* Given $(\\Omega,\\mathcal{A},P)$, a random variable is a function $X:\\Omega\\rightarrow\\mathbf{R}$ s.t. $\\{\\omega\\in\\Omega:X(\\omega)\\leq x\\}$ (or $P(X\\leq x)$) $\\in \\mathcal{A}, \\forall x\\in\\mathbf{R} $.\n",
    "* The $CDF$ of a random variable $X$ is the function $F:\\mathbf{R}\\rightarrow [0,1]$, s.t. $F(x)=P(X\\leq x)$.\n",
    "* The *distribution* of $X$ is the probability measure $P^X$ on $\\mathbf{R}$ s.t. $P^X = P(X\\in\\mathcal{A}), \\forall \\mathcal{A}\\in \\mathcal{B}(\\mathbf{R})$.\n",
    "* The function of a r.v. is itself a r.v.: $g(X)$ is a r.v. if $X$ is a r.v. and $g: \\mathbf{R}\\rightarrow\\mathbf{R}$ is a measureable function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Basic Types **\n",
    "\n",
    "* *Discrete*:\n",
    "    * A r.v. $X$ is discrete if $X(\\Omega)$ is countable.\n",
    "    * The *probability mass function (PMF)* of a discrete r.v. $X$ is the function $\\mathcal{P}:\\mathbf{R}\\rightarrow[0,1]$ s.t. $\\mathcal{P}(x) = P(X=x)$.\n",
    "    * Ex. $X\\sim Bernoulli(\\alpha), \\alpha\\in[0,1], \\mathcal{P}(1) = \\alpha, \\mathcal{P}(0)=1-\\alpha$ (prob. of the outcome of 1 coinflip being $0$ or $1$).\n",
    "    * Ex. $X\\sim Binomial(n,\\alpha), \\alpha\\in[0,1], \\mathcal{P}=\\binom{n}{k}\\alpha^k(1-\\alpha)^{n-k}$ (prob. of $k$ heads/tails out of $n$ coinflips).\n",
    "    * Ex. $X\\sim Geometric(\\alpha), \\alpha\\in[0,1], \\mathcal{P}(k) = (1-\\alpha)^{k-1}\\alpha$ (prob. of $k$ coinflips until getting a head/tail).\n",
    "    * Ex. $X\\sim Poisson(\\lambda), \\lambda \\geq 0, \\mathcal{P}(k) = e^{-\\lambda}\\frac{\\lambda^k}{k!}$, where $k \\in\\{0,1,...,\\}$ (prob. of $k$ customers arriving at a store in 1 hr if the rate of arrival per hr is $\\lambda$, if the times between arrivals are indep.).\n",
    "    \n",
    "* *Continuous*:\n",
    "    * The *probability density function* $f$ if $F(x) = P(X\\leq x) = \\int_{-\\infty}^x f(u)du, \\forall x \\in \\mathbf{R}$ for some integrable $f:\\mathbf{R}\\rightarrow [0,\\infty]$.\n",
    "    * The *indicator function* $I_A(x) = \\begin{cases} 1 \\quad if x\\in A \\\\ 0 \\quad otherwise\\end{cases}$.\n",
    "    * Ex. $X\\sim Uniform(a,b), a<b: f(x)=\\frac{1}{b-a}, x\\in[a,b]$ and $f(x)=0$ otherwise.\n",
    "    * Ex. $X\\sim Exponential(\\lambda), \\lambda>0: f(x) = \\lambda e^{-\\lambda x}, x\\geq 0$, and $0$ otherwise (prob. of the lifetime $x$ of a lightbulb given the average is $\\frac{1}{\\lambda}$).\n",
    "    * Ex. $X\\sim Beta(\\alpha,\\beta), \\alpha, \\beta > 0: f(x) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}, x\\in[0,1]$, and $0$ elsewhere (prob. of a prob. between $0$ and $1$).\n",
    "    * Ex. $X\\sim Normal(\\mu,\\sigma^2), \\mu\\in\\mathbf{R},\\sigma^2>0: f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-(x-\\mu)^2/2\\sigma^2}, x\\in\\mathbf{R}$ (prob. of a value $x$ appearing).\n",
    "\n",
    "** Multiple R.V. **\n",
    "\n",
    "* Given $(\\Omega,\\mathcal{A},P)$, a *random vector* is a measure $X:\\Omega\\rightarrow\\mathbf{R}^d$, $d\\in\\{1,2,...\\}$.\n",
    "* A *discrete r.v.* $X\\in\\mathbf{R}^d$ is s.t. $X(\\Omega)$ is countable.\n",
    "* The *joint distribution* of a discrete r.v. $X\\in\\mathbf{R}^d$ is the $PMF$ $\\mathcal{P}:\\mathbf{R}^d\\rightarrow[0,1]$ s.t. $\\mathcal{P}(x) = P(X=x), \\forall x\\in\\mathbf{R}^d$.\n",
    "\n",
    "** Marginal ** \n",
    "\n",
    "* Fixing $(X,Y)\\in\\mathbf{R}^2$, with $\\mathcal{P}(x,y) = P(X=x,Y=y)$, the *marginal* $PMF$ of $X$ is $\\mathcal{P}_X(x)=P(X=x)$, where $\\mathcal{P}_X(x)=\\sum_{y\\in Y}\\mathcal{P}(x,y)$. \n",
    "\n",
    "** Covariance **\n",
    "\n",
    "* The *covariance* of r.v.s $X$ and $Y$ is $Cov(X,Y) = E[(X-E(X))(Y-E(Y))]$.\n",
    "    * $Cov(X,X) = \\sigma^2(X)$,\n",
    "    * $Cov(X,Y) = E(XY) - E(X)E(Y)$,\n",
    "    * $X,Y$ indep. $\\Rightarrow Cov(X,Y) = 0$.\n",
    "    \n",
    "** Correlation **\n",
    "\n",
    "* The *pearson correlation efficient* of r.v.s $X$ and $Y$ is $\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Exp. Var. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expectation **\n",
    "\n",
    "* **Definition**:\n",
    "    * Discrete Case: The expectation of a discrete r.v. $X$ with $PMF$ $\\mathcal{P}$ is $E(X) = \\sum_xx\\mathcal{P}(x)$ when this sum is well-defined (exp. is not defined otherwise).\n",
    "    * Continuous Case: The expectation of a continuous r.v. $X$ with $PDF$ $f$ is $E(X) = \\int_{-\\infty}^{\\infty}xf(x)dx$ when this sum is well-defined (exp. is not defined otherwise).\n",
    "    \n",
    "* **Expectation Rule**:\n",
    "    * If $X$ is a r.v. and $g: \\mathbf{R}\\rightarrow\\mathbf{R}$, then,\n",
    "        * $E_g(X) = \\sum_x g(x)\\mathcal{P}(x)$ if $X$ is discrete with $PMF$ $\\mathcal{P}$. \n",
    "        * $E_g(X) = \\int_{-\\infty}^{\\infty} g(x)f(x)dx$ if $X$ is continuous with $PDF$ $f$.\n",
    "\n",
    "* **Properties**\n",
    "    * *Linearity*\n",
    "        * $E(a) = a \\forall a\\in\\mathbf{a}$,\n",
    "        * $E(aX) = aE(X), \\forall a\\in\\mathbf{a}$, \n",
    "        * $E(X+Y) = E(X) + E(Y)$, (gen. $E(\\sum_{i=1}^{\\infty}X_i) = \\sum_{i=1}^{\\infty}E(X_i)$).\n",
    "    * *Order Preservation*\n",
    "        * If $X\\geq 0$, then $E(X)\\geq 0$,\n",
    "        * If $X\\leq Y$, then $E(X)\\leq E(Y)$.\n",
    "    * $E(I_A(X)) = P(X\\in A)$.\n",
    "\n",
    "** Other Important Stats **\n",
    "\n",
    "* *Mean*: The mean $\\mu(x)$ is $E(X)$.\n",
    "* *Variance*: The variance $\\sigma^2(X)$ (or $Var(X)$) is $E[(X-E(X))^2]$.\n",
    "* *Moment*: \n",
    "    * The $k$th moment ($k\\in\\{1,2,...\\}$ $m_k(X)$ is $E(X^k)$,\n",
    "    * The $k$th central moment is $E[(X-E(X))^k]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Laws & Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Indep. & Iden. Distributed (i.i.d) **\n",
    "\n",
    "* $X_1,...,X_n$ are *i.i.d* if if they are indep. and $\\mathcal{P}_{X_1} = \\mathcal{P}_{X_n}$.\n",
    "\n",
    "** Law of Large Number (LLN) **\n",
    "\n",
    "* Let $X_1,...,X_n$ be i.i.d with mean $\\mu$ and variance $0<\\sigma^2<\\infty$, $\\frac{1}{n}\\sum_{i=1}^{n}X_i \\rightarrow \\mu, w.p.1$ (i.e. $P(lim_{n\\rightarrow\\infty}\\frac{1}{n}\\sum_{i=1}^{n}X_i=\\mu)=1$).\n",
    "\n",
    "** Central Limit Theorem (CLT) **\n",
    "\n",
    "* Given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined (finite) expected value and finite variance, will be approximately normally distributed, regardless of the underlying distribution.\n",
    "* $\\sqrt{\\frac{n}{\\sigma^2}}[(\\frac{1}{n}\\sum_{i=1}^nX_i)-\\mu]\\rightarrow_D N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Definition **\n",
    "\n",
    "* A r.v. $X\\in\\mathbf{R}^n$ is (multivariate) Gaussian if any linear combination of $a$ and $X$ ($\\forall a\\in\\mathbf{R}^n$) is (Univariate) Gaussian. (i.e. $a^TX = \\sum_{i=1}^na_iX_i$ is Gaussian).\n",
    "* $X\\sim N(\\mu,C)$ ($\\mu\\in\\mathbf{R}^n$, $C$ is a pos. semdef. matrix) is Gaussian with $E(X_i)=\\mu$ and $Cov(X_i,X_j)=C_{ij}$, where $Cov(X) = E(XX^T)-E(X)E(X)^T$. (pos. semdef.: all eigenvalues $\\lambda_i\\geq 0$).\n",
    "* $X\\sim N(\\mu,C)$ is *degenerate* if $detC=0$.\n",
    "\n",
    "** Properties **\n",
    "\n",
    "* If $X\\in\\mathbf{R}^n$ is Gaussian, then $X_i$ and $X_j$ are indep. iff $Cov(X_i,X_j) = 0$. Graphically, a set of indep. Gaussians are *axis-aligned* clusters.\n",
    "* A set of univariate Gaussians $X_1,...,X_n$ only implies their joint distribution being a Gaussian too when they are indep.\n",
    "* A Gaussian r.v. $X\\sim N(\\mu,C)$ has a density iff it is nondegenerate (i.e. $detC\\neq 0$). $f(x) = \\frac{1}{\\sqrt{det(2\\pi C)}}exp\\left\\{-\\frac{1}{2}(x-\\mu)^TC^{-1}(x-\\mu)\\right\\}$.\n",
    "* (Affinity) Any *affine transformantion* (i.e. a function of the form $f(x) = ax+b$) of a Gaussian is Gaussian. That is, if $X\\sim N(\\mu,C)$, then $AX+b\\sim N(A\\mu+b,ACA^T),\\forall \\mu\\in\\mathbf{R}^n,C\\in\\mathbf{R}^{n\\times n}, A\\in\\mathbf{R}^{m\\times n},b\\in\\mathbf{R}^m$.\n",
    "* (Construction) To construct a Gaussian ..., $X_1,...,X_n\\sim N(0,1)$ indep. $\\Rightarrow X\\sim N(0,I) \\Rightarrow AX+\\mu\\sim N(\\mu,C)$ where $C=AA^T,\\forall \\mu\\in\\mathbf{R}^n,A\\in\\mathbf{R}^{m\\times n}$.\n",
    "* (Sphering, inverse of Construction) If $C$ is pos. def., then $Y\\sim N(\\mu,C)\\Rightarrow A^{-1}(Y-\\mu)\\sim N(0,I)$, where $C=AA^T$.\n",
    "\n",
    "** Marginal **\n",
    "\n",
    "* If $X = (X_1,X_2)^T\\in\\mathbf{R}^2$ is a Gaussian, then the marginals $X_1$,$X_2$ are Gaussians too.\n",
    "\n",
    "** Conditional **\n",
    "\n",
    "* If $X = (X_1,X_2)^T\\in\\mathbf{R}^2$ is a Gaussian, then the conditional $(X_1|X_2=x_2)$ is Gaussian too.\n",
    "* $(X_a|X_b=x_b)\\sim N(m,D)$, where $m=\\mu_a+C_{ab}C_{bb}^{-1}(x_b-\\mu_b), D = C_{aa}-C_{ab}C_{bb}^{-1}C_{ba}$.\n",
    "\n",
    "** Sum of Indep. Gaussians **\n",
    "\n",
    "* If $X\\sim N(\\mu_x,C_x)$, $Y\\sim N(\\mu_y,C_y)$ indep., then $X+Y \\sim N(\\mu_x+\\mu_y,C_x+C_y)$.\n",
    "* Let $a\\in\\mathbf{R}^n, a^T(X+Y) = a^TX+a^TY$. (multivariate Gaussian $\\Rightarrow$ univariate Gaussians).\n",
    "    * $E(X+Y) = E(X)+E(Y) = \\mu_x+\\mu_y$,\n",
    "    * $Cov(X+Y) = Cov(X) + Cov(Y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
